{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "PMSin0VBRQtz",
        "yreRxXBn0Giv",
        "q5dDoTa-fEQo",
        "ZRINshSmcy1C",
        "8N7813-DTUvN",
        "0U-w3c7JFdHT",
        "W8Nr0eIJFicM",
        "ymLQIETzyyAK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### General Imports"
      ],
      "metadata": {
        "id": "fNSo-Wxi8b1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "5WTuF-o08ffq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LimQ2k8NVX3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"/content/drive/MyDrive/Personal details/Dataset/els_02_12_byf3stu_v1_0.csv\"\n",
        "\n",
        "df = pd.read_csv(path)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "uKCDeoqaW2qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(10)"
      ],
      "metadata": {
        "id": "_oEu3ACVMATm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "|# # Clustered heatmap for the entire correlation matrix\n",
        "# plt.figure(figsize=(14, 12))\n",
        "# sns.clustermap(df.corr(), cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "# plt.title(\"Clustered Correlation Matrix Heatmap\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "Rn_Qmjn1O9kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 1**"
      ],
      "metadata": {
        "id": "PMSin0VBRQtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list the total number of features in this dataframe\n",
        "\n",
        "num_features = len(df.columns)\n",
        "print(f\"Number of features: {num_features}\")\n"
      ],
      "metadata": {
        "id": "TmyCPdNqYi9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count total numbers of rows in this dataset\n",
        "\n",
        "num_rows = len(df)\n",
        "print(f\"Number of rows: {num_rows}\")\n"
      ],
      "metadata": {
        "id": "YRHijmT1b3wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display\n",
        "\n",
        "df[['STU_ID', 'STRAT_ID', 'PSU','BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'F1TXMSTD' ]].head(5)\n"
      ],
      "metadata": {
        "id": "6qDkXP2ccSy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping values to labels\n",
        "# This data conversion was done for the purpose of PowerBi analysis\n",
        "sex_mapping = {1: 'male', 2: 'female', -4: 'non-respondent', -8: 'legit skip'}\n",
        "race_mapping = {1: 'native', 2: 'asian', 3: 'black', 4: 'hispanic (no race)',\n",
        "                5: 'hispanic (race)', 6: 'multi (non-hispanic)', 7: 'white',\n",
        "                -4: 'non-respondent', -8: 'legit skip'}\n",
        "lang_mapping = {0: 'no', 1: 'yes', -4: 'non-respondent', -8: 'legit skip', -9: 'missing'}\n"
      ],
      "metadata": {
        "id": "nYOoJLNFgW2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select specified columns and replace values\n",
        "selected_df = df[['STU_ID', 'STRAT_ID', 'PSU', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "selected_df['BYSEX'] = selected_df['BYSEX'].replace(sex_mapping)\n",
        "selected_df['BYRACE'] = selected_df['BYRACE'].replace(race_mapping)\n",
        "selected_df['BYSTLANG'] = selected_df['BYSTLANG'].replace(lang_mapping)\n"
      ],
      "metadata": {
        "id": "eLyErpLEhB9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows of the new DataFrame\n",
        "selected_df.head()\n"
      ],
      "metadata": {
        "id": "q-TgOQyDinr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the new DataFrame to a CSV file\n",
        "selected_df.to_csv('selected_data_with_replaced_values.csv', index=False)"
      ],
      "metadata": {
        "id": "8GfOVxaVjOjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the entire DataFrame\n",
        "missing_values = selected_df.isnull().sum()\n",
        "\n",
        "# Display the count of missing values for each column\n",
        "print(\"Missing Values:\\n\", missing_values)\n"
      ],
      "metadata": {
        "id": "JEN0Q-nCvD2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Distribution of Gender\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='BYSEX', data=selected_df)\n",
        "plt.title('Distribution of Gender')\n",
        "plt.xlabel('Gender (BYSEX)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-O2RV6lfwond"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ethnicity/Race Distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "selected_df['BYRACE'].value_counts().plot(kind='bar')\n",
        "plt.title('Ethnicity/Race Distribution')\n",
        "plt.xlabel('Ethnicity/Race (BYRACE)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7QbD02W-xgR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# English Proficiency\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='BYSTLANG', data=selected_df)\n",
        "plt.title('Distribution of English Proficiency')\n",
        "plt.xlabel('English Proficiency (BYSTLANG)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NfcTum0HxiQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "yreRxXBn0Giv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "AsjJUENKxjt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df1 = df[['STU_ID', 'STRAT_ID', 'PSU', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'F1TXMSTD']].copy()"
      ],
      "metadata": {
        "id": "OWF0KT1Uy6M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selected features and target\n",
        "X = selected_df1.drop(columns=['F1TXMSTD'])\n",
        "y = selected_df1['F1TXMSTD']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Vn4DNbXvyk-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Ryf23u_wzD5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "UDbErNYjzLkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C5trIGxJz2G6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Parameter Tuning and Random Forest Regressor, Very High mean square error (MSC), try another model"
      ],
      "metadata": {
        "id": "vSRSyetN0rqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the best hyper parameters\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# # Define the model and the hyperparameter grid\n",
        "# model = RandomForestRegressor()\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 150],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4]\n",
        "# }\n",
        "\n",
        "# # Create the GridSearchCV object\n",
        "# grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "\n",
        "# # Fit the grid search to the data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Print the best hyperparameters\n",
        "# print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# # Get the best model\n",
        "# best_model = grid_search.best_estimator_\n",
        "\n",
        "# # Make predictions with the best model\n",
        "# best_predictions = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "dQoWs9Yy0EXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Hyperparameter tuning was implemented to optimize the performance of a Random Forest Regressor in predicting F1TXMSTD. By adjusting key parameters like the number of estimators and tree depth, the goal was to enhance predictive accuracy, avoid overfitting or underfitting, improve generalization to new data, and boost computational efficiency. The process aimed to fine-tune the model for optimal results in handling the given dataset.\n"
      ],
      "metadata": {
        "id": "Q1tsre0HBNDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Replace X_train, y_train with your actual training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_hyperparameters = {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "\n",
        "# Create a RandomForestRegressor with the best hyperparameters\n",
        "best_model = RandomForestRegressor(**best_hyperparameters, random_state=42)\n",
        "\n",
        "# Train the model on the entire training dataset\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error on Test Set: {mse}')\n"
      ],
      "metadata": {
        "id": "6E-f1ADQAamp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe 2, which excludes STRAT_ID and PSU"
      ],
      "metadata": {
        "id": "AnvrMuriS_16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df2 = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'F1TXMSTD']].copy()"
      ],
      "metadata": {
        "id": "va_IrWnCSvLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mt Reference:\n",
        "\n",
        "Student ID is composed of the 4-digit School ID (which consists of\n",
        "the 3-digit Stratum and 1-digit PSU) and a 2-digit sequential\n",
        "student code within school.\n",
        "Stratum (STRAT_ID) and PSU are embedded in STU_ID for ease of use\n",
        "in certain variance estimation programs"
      ],
      "metadata": {
        "id": "fR7xe_uRV97a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selected features and target\n",
        "X = selected_df2.drop(columns=['F1TXMSTD'])\n",
        "y = selected_df2['F1TXMSTD']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "dYmH_Hl-U35J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "BSRfj64qU-xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "3ecDPOp0VCQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Replace X_train, y_train with your actual training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Best hyperparameters\n",
        "best_hyperparameters = {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "\n",
        "# Create a RandomForestRegressor with the best hyperparameters\n",
        "best_model = RandomForestRegressor(**best_hyperparameters, random_state=42)\n",
        "\n",
        "# Train the model on the entire training dataset\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance on the test set\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error on Test Set: {mse}')\n"
      ],
      "metadata": {
        "id": "9WgDY0vIVVgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 2\n",
        "\n",
        "# Variable Selection for Matching\n",
        "\n",
        "In any analysis, selecting the right set of variables is crucial. Here, we identify and describe the key variables for matching in our dataset.\n",
        "\n",
        "## 1. Identification Variables\n",
        "\n",
        "### 1.1 STU_ID: Student ID (Unique)\n",
        "- **Description**: Unique identifier for each student.\n",
        "- **Role**: Used for individual-level identification.\n",
        "\n",
        "### 1.2 SCH_ID: School ID (Restricted Data)\n",
        "- **Description**: Identifier for the school (Note: Restricted Data).\n",
        "- **Role**: Potentially useful for school-level matching.\n",
        "\n",
        "### 1.3 STRAT_ID: Stratum ID\n",
        "- **Description**: Identifier for the stratum.\n",
        "- **Role**: Used to define strata for sampling.\n",
        "\n",
        "### 1.4 PSU: Primary Sampling Unit (School)\n",
        "- **Description**: Identifier for the primary sampling unit (school).\n",
        "- **Role**: Used in the sampling design.\n",
        "\n",
        "## 2. Demographic Variables\n",
        "\n",
        "### 2.1 BYSEX: Gender\n",
        "- **Description**: 1 = Male, 2 = Female, -4/-8 = Non-respondent/Legit Skip.\n",
        "- **Role**: Consider for gender-based matching.\n",
        "\n",
        "### 2.2 BYRACE: Race\n",
        "- **Description**: Various codes for different racial categories.\n",
        "- **Role**: Consider for race-based matching.\n",
        "\n",
        "### 2.3 BYSTLANG: English Proficiency\n",
        "- **Description**: 0 = No, 1 = Yes, -4/-8/-9 = Non-respondent/Legit Skip/Missing.\n",
        "- **Role**: Consider for language-based matching.\n",
        "\n",
        "### 2.4 YDOB_P: Year/Month of Birth\n",
        "- **Description**: 4-digit year, 2-digit month.\n",
        "- **Role**: May be useful for age-based matching.\n",
        "\n",
        "## 3. Educational Variables\n",
        "\n",
        "### 3.1 BYMOTHED: Mother's Education Level\n",
        "- **Description**: 1-8 represent different education levels, -4/-8/-9 = Non-response/Legit Skip/Missing.\n",
        "- **Role**: Consider for parental education-based matching.\n",
        "\n",
        "### 3.2 BYFATHED: Father's Education Level\n",
        "- **Description**: 1-8 represent different education levels, -4/-8/-9 = Non-response/Legit Skip/Missing.\n",
        "- **Role**: Consider for parental education-based matching.\n",
        "\n",
        "## 4. Academic Performance Variables\n",
        "\n",
        "### 4.1 BYSES1: Socioeconomic Status\n",
        "- **Description**: Ranges between -2.11 and 1.82, -4/-8 = Non-response/Legit Skip.\n",
        "- **Role**: Consider for socioeconomic status-based matching.\n",
        "\n",
        "### 4.2 BYTXMSTD: Math Score, 10th Grade\n",
        "- **Description**: Range between 19.38 and 86.68, -8 = Legit Skip.\n",
        "- **Role**: Consider for academic performance-based matching.\n",
        "\n",
        "### 4.3 BYTXRSTD: Reading Score, 10th Grade\n",
        "- **Description**: Range between 22.57 and 78.76, -8 = Legit Skip.\n",
        "- **Role**: Consider for academic performance-based matching.\n",
        "\n",
        "### 4.4 F1TXMSTD: Math Score, 12th Grade\n",
        "- **Description**: Range between 19.82 and 79.85, -8 = Legit Skip.\n",
        "- **Role**: Consider for academic performance-based matching.\n"
      ],
      "metadata": {
        "id": "eFrOOTVqTKfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual Parameter optimisation"
      ],
      "metadata": {
        "id": "q5dDoTa-fEQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()"
      ],
      "metadata": {
        "id": "TJKDGUjrReYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df.head(5)"
      ],
      "metadata": {
        "id": "54vGuHbBR__N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the total number of rows in BYSEX column with values -4 or -8\n",
        "non_responses_sex = selected_df[selected_df['BYSEX'].isin([-4, -8])].shape[0]\n",
        "\n",
        "print(f'Total number of rows in BYSEX column with values -4 or -8: {non_responses_sex}')\n"
      ],
      "metadata": {
        "id": "9M13R1PVVFPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4 and -8 in BYSEX column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYSEX'] = selected_df['BYSEX'].replace([-4, -8], -999)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYSEX'].value_counts()\n"
      ],
      "metadata": {
        "id": "kM6HXGlGWIqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4 and -8 in BYRACE column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYRACE'] = selected_df['BYRACE'].replace([-4, -8], -999)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYRACE'].value_counts()"
      ],
      "metadata": {
        "id": "ZmxyllELWaF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4, -8, -9 in BYSTLANG column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYSTLANG'] = selected_df['BYSTLANG'].replace([-4, -8, -9], -999)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYSTLANG'].value_counts()"
      ],
      "metadata": {
        "id": "80qsrvcSWtvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4, -8, -9 in BYMOTHED column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYMOTHED'] = selected_df['BYMOTHED'].replace([-4, -8, -9], -999)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYMOTHED'].value_counts()"
      ],
      "metadata": {
        "id": "_tNhd1c2XPKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4, -8, -9 in BYFATHED column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYFATHED'] = selected_df['BYFATHED'].replace([-4, -8, -9], -999)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYFATHED'].value_counts()"
      ],
      "metadata": {
        "id": "5gdZGt-7XQS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace -4, -8, -9 in BYSES1 column with a common value (e.g., -999 for missing)\n",
        "selected_df['BYSES1'] = selected_df['BYSES1'].replace([-4, -8, -9], 0)\n",
        "\n",
        "# Verify the changes\n",
        "selected_df['BYSES1'].value_counts()"
      ],
      "metadata": {
        "id": "L8gPky63XagX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the changes\n",
        "selected_df['BYTXMSTD'].value_counts()"
      ],
      "metadata": {
        "id": "_27JdItQYIb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()"
      ],
      "metadata": {
        "id": "18Fg4BkiZoJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "QU_cGycucV6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#  df is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
        "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train_imputed, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test_imputed)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "IULvI6dFZ1eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Linear Regression after Dropping NaN rows\n"
      ],
      "metadata": {
        "id": "ZRINshSmcy1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG','BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "num_rows = len(selected_df_cleaned)\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df_cleaned['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "VpU0Nu07cx7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What's surprising is , without Student ID accuracy is still 81%"
      ],
      "metadata": {
        "id": "14I385-LKO9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Calculate R-squared\n",
        "r_squared = r2_score(y_test, predictions)\n",
        "\n",
        "print(f'R-squared: {r_squared}')\n"
      ],
      "metadata": {
        "id": "jyTda44mdn3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyper Paramter Tuning, GridSearch CV"
      ],
      "metadata": {
        "id": "U54CQ2nbezJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, make_scorer\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG','BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df_cleaned['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Define hyperparameters to search\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [False],  # 'positive' is a hyperparameter for LinearRegression\n",
        "    'copy_X': [True, False]\n",
        "}\n",
        "\n",
        "# Define the scoring metric (e.g., mean squared error)\n",
        "scoring = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(model, param_grid, scoring=scoring, cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error of the Best Model: {mse}')\n"
      ],
      "metadata": {
        "id": "8p4w2MDTfs6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R-squared\n",
        "r_squared = r2_score(y_test, predictions)\n",
        "print(f'R-squared: {r_squared}')"
      ],
      "metadata": {
        "id": "WviYQ6M2g0gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mfOjNeHQh0NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Regressor"
      ],
      "metadata": {
        "id": "m_b_9Ab8h2kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG','BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('BYTXMSTD', axis=1)\n",
        "y = selected_df_cleaned['BYTXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Random Forest Regressor model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "mSptPwJzh350"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 300, 500],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(rf_model, param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Make predictions on the test set using the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_predictions = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_mse = mean_squared_error(y_test, best_predictions)\n",
        "print(f'Mean Squared Error of the Best Model: {best_mse}')\n"
      ],
      "metadata": {
        "id": "W-hcqm2Fiylg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Best Hyperparameters: {'max_depth': 10, 'n_estimators': 200}\n",
        "\n",
        "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
        "\n",
        "Mean Squared Error of the Best Model: 20.649908255679446\n",
        "\n",
        "2. Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 500}\n",
        "\n",
        "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
        "\n",
        "Mean Squared Error of the Best Model: 20.405364924774876"
      ],
      "metadata": {
        "id": "zc9vFOxej-FL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Networks"
      ],
      "metadata": {
        "id": "GxSl_E6QkLTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG','BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('BYTXMSTD', axis=1)\n",
        "y = selected_df_cleaned['BYTXMSTD']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)  # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mse, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Squared Error: {mse}, Mean Absolute Error: {mae}')\n"
      ],
      "metadata": {
        "id": "APFdSE6ckCXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear activation function"
      ],
      "metadata": {
        "id": "VRZaywiileWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uh_OkZKImaSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3\n"
      ],
      "metadata": {
        "id": "8N7813-DTUvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame with 6000 features\n",
        "# Select a subset of features for better visualization\n",
        "subset_features = df.sample(n=20, axis=1, random_state=42)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = subset_features.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix Heatmap (Subset of Features)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qod-YEC2hB8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame with 6000 features\n",
        "# Calculate the correlation matrix with respect to the target variable\n",
        "correlation_with_target = df.corrwith(df['F1TXMSTD'])\n",
        "\n",
        "# Create a DataFrame for the correlation values\n",
        "correlation_df = pd.DataFrame({'Correlation with F1TXMSTD': correlation_with_target})\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_df.transpose(), annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
        "plt.title(\"Correlation with F1TXMSTD - Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bIvp2MXkiMW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'df' is your DataFrame with 6000 features\n",
        "# Calculate the correlation with the target variable\n",
        "correlation_with_target = df.corrwith(df['F1TXMSTD']).abs()\n",
        "\n",
        "# Select the top 10 features with the highest correlation\n",
        "top_features = correlation_with_target.nlargest(30).index\n",
        "\n",
        "# Extract the corresponding subset of the DataFrame\n",
        "subset_features = df[top_features]\n",
        "\n",
        "# Calculate the correlation matrix for the selected features\n",
        "correlation_matrix = subset_features.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(18, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Top 10 Features with Highest Correlation with F1TXMSTD - Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RVjhK1EpipVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame with 6000 features\n",
        "# Calculate the correlation with the target variable\n",
        "correlation_with_target = df.corrwith(df['F1TXMSTD'])\n",
        "\n",
        "# Create a DataFrame for the correlation values\n",
        "correlation_df = pd.DataFrame({'Feature': correlation_with_target.index, 'Correlation with F1TXMSTD': correlation_with_target.abs()})\n",
        "\n",
        "# Sort the DataFrame by absolute correlation values in descending order\n",
        "sorted_correlation_df = correlation_df.sort_values(by='Correlation with F1TXMSTD', ascending=False)\n",
        "\n",
        "# Display the top 10 correlations\n",
        "top_correlations = sorted_correlation_df.head(100)\n",
        "print(\"Top 10 Features with Highest Correlation with F1TXMSTD:\")\n",
        "print(top_correlations)\n"
      ],
      "metadata": {
        "id": "CrhEhh8Wt4FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the correlation with the target variable\n",
        "correlation_with_target = df.corrwith(df['F1TXMSTD'])\n",
        "\n",
        "# Extract the correlation value for the specific feature 'XXXXXXX'\n",
        "correlation_xxx = correlation_with_target['BYTX1MPP']\n",
        "\n",
        "print(f\"Correlation of 'F1NELS2M' with 'F1TXMSTD': {correlation_xxx}\")\n"
      ],
      "metadata": {
        "id": "v1N7Hf7J0Tp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display 10 random values from the 'F1NELS2M' column\n",
        "random_values = df['F1NELS2M'].head(10)\n",
        "print(\"10 Random Values from 'F1NELS2M':\")\n",
        "print(random_values)\n"
      ],
      "metadata": {
        "id": "KhllOsfYvVvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression"
      ],
      "metadata": {
        "id": "0U-w3c7JFdHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "num_rows = len(selected_df_cleaned)\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df_cleaned['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Add a new column 'Predicted_F1TXMSTD' to your DataFrame\n",
        "selected_df_cleaned['Predicted_F1TXMSTD'] = model.predict(X)\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "print(selected_df_cleaned.head())\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# 'selected_df_cleaned' is your DataFrame with the predicted values\n",
        "## selected_df_cleaned.to_csv('output_file.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "zL1P8xZrTXAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'selected_df_cleaned' is your DataFrame\n",
        "correlation_matrix = selected_df_cleaned.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "hS631_C1XH-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BaBYRcthX8W8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'correlation_matrix' is your correlation matrix\n",
        "#correlation_matrix.to_csv('correlation_matrix.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "JmJ9DZNZYEOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression:**\n",
        "\n",
        "Formula: \\(y = mx + b\\)\n",
        "\n",
        "- \\(y\\) is the dependent variable (target),\n",
        "- \\(x\\) is the independent variable (predictor),\n",
        "- \\(m\\) is the slope of the line, and\n",
        "- \\(b\\) is the y-intercept.\n",
        "\n",
        "**Basic Explanation:** Linear regression models the relationship between a single independent variable and a dependent variable as a straight line. The slope (\\(m\\)) represents the change in the dependent variable for a one-unit change in the independent variable.\n",
        "\n",
        "**Multiple Regression:**\n",
        "\n",
        "Formula: \\(y = b_0 + b_1x_1 + b_2x_2 + \\ldots + b_nx_n\\)\n",
        "\n",
        "- \\(y\\) is the dependent variable,\n",
        "- \\(x_1, x_2, \\ldots, x_n\\) are the independent variables,\n",
        "- \\(b_0\\) is the y-intercept,\n",
        "- \\(b_1, b_2, \\ldots, b_n\\) are the coefficients representing the change in \\(y\\) for a one-unit change in the corresponding \\(x\\) variable.\n",
        "\n",
        "**Basic Explanation:** Multiple regression extends the concept of linear regression to include multiple independent variables. It models the relationship between the dependent variable and multiple predictors. Each coefficient (\\(b_i\\)) represents the change in the dependent variable while holding other variables constant.\n",
        "\n",
        "In both cases, the goal is to find the values of the coefficients that minimize the difference between the predicted values and the actual values of the dependen\n"
      ],
      "metadata": {
        "id": "xIyY7r_WGHcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Regression"
      ],
      "metadata": {
        "id": "W8Nr0eIJFicM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "num_rows = len(selected_df_cleaned)\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df_cleaned['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Train the Multiple Regression model\n",
        "multiple_regression_model = LinearRegression()\n",
        "multiple_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = multiple_regression_model.predict(X_test)\n",
        "\n",
        "# Add a new column 'Predicted_F1TXMSTD' to your DataFrame\n",
        "selected_df_cleaned['Predicted_F1TXMSTD'] = multiple_regression_model.predict(X)\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "print(selected_df_cleaned.head())\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# 'selected_df_cleaned' is your DataFrame with the predicted values\n",
        "## selected_df_cleaned.to_csv('output_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "SM4UWIH3Fk5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'R-squared Score: {r2}')"
      ],
      "metadata": {
        "id": "vQIXoWgmx6Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'selected_df_cleaned' is your DataFrame\n",
        "correlation_matrix = selected_df_cleaned.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "\n",
        "print(correlation_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "voKYhuqpG7LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting a heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DJ9M1nuUHpaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the absolute difference between actual and predicted values\n",
        "selected_df_cleaned['Abs_Difference'] = np.abs(selected_df_cleaned['F1TXMSTD'] - selected_df_cleaned['Predicted_F1TXMSTD'])\n",
        "\n",
        "# Color-coding based on the difference\n",
        "selected_df_cleaned['Color'] = pd.cut(selected_df_cleaned['Abs_Difference'],\n",
        "                                     bins=[0, 5, 10, 20, 100],\n",
        "                                     labels=['±5', '±10', '±20', '>20'])\n",
        "\n",
        "# Visualize the difference between actual and predicted values using a scatter plot with color-coding\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter_plot = sns.scatterplot(x='F1TXMSTD', y='Predicted_F1TXMSTD', hue='Color', data=selected_df_cleaned, palette=['green', 'yellow', 'orange', 'red'])\n",
        "plt.title('Actual vs. Predicted F1TXMSTD with Color-Coding')\n",
        "plt.xlabel('Actual F1TXMSTD')\n",
        "plt.ylabel('Predicted F1TXMSTD')\n",
        "plt.legend(title='Difference')\n",
        "plt.show()\n",
        "\n",
        "# Get count of points in each category\n",
        "category_counts = selected_df_cleaned['Color'].value_counts()\n",
        "print(\"\\nCount of points in each category:\")\n",
        "print(category_counts)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'\\nMean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "or7bkqbPHdfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##New Feature - Multipel Regression"
      ],
      "metadata": {
        "id": "ymLQIETzyyAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "#BYOCCHS - Occupation right after high school-coded\n",
        "#F1NELS2M - Mathematics—NELS-equated 12th-grade estimated\n",
        "\n",
        "# 'df' is your DataFrame\n",
        "selected_df = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD','BYOCCHS', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "selected_df.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "selected_df_cleaned = selected_df.dropna()\n",
        "\n",
        "num_rows = len(selected_df_cleaned)\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_df_cleaned.drop('F1TXMSTD', axis=1)\n",
        "y = selected_df_cleaned['F1TXMSTD']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Multiple Regression model\n",
        "multiple_regression_model = LinearRegression()\n",
        "multiple_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = multiple_regression_model.predict(X_test)\n",
        "\n",
        "# Add a new column 'Predicted_F1TXMSTD' to your DataFrame\n",
        "selected_df_cleaned['Predicted_F1TXMSTD'] = multiple_regression_model.predict(X)\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "print(selected_df_cleaned.head())\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "# 'selected_df_cleaned' is your DataFrame with the predicted values\n",
        "## selected_df_cleaned.to_csv('output_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "DxW9-Ycfy3AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate R-squared score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'R-squared Score: {r2}')"
      ],
      "metadata": {
        "id": "9xSYH-59zBe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 'selected_df_cleaned' is your DataFrame\n",
        "correlation_matrix = selected_df_cleaned.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "\n",
        "print(correlation_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "DoIP-owFzExf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate the absolute difference between actual and predicted values\n",
        "selected_df_cleaned['Abs_Difference'] = np.abs(selected_df_cleaned['F1TXMSTD'] - selected_df_cleaned['Predicted_F1TXMSTD'])\n",
        "\n",
        "# Color-coding based on the difference\n",
        "selected_df_cleaned['Color'] = pd.cut(selected_df_cleaned['Abs_Difference'],\n",
        "                                     bins=[0, 5, 10, 20, 100],\n",
        "                                     labels=['±5', '±10', '±20', '>20'])\n",
        "\n",
        "# Visualize the difference between actual and predicted values using a scatter plot with color-coding\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter_plot = sns.scatterplot(x='F1TXMSTD', y='Predicted_F1TXMSTD', hue='Color', data=selected_df_cleaned, palette=['green', 'yellow', 'orange', 'red'])\n",
        "plt.title('Actual vs. Predicted F1TXMSTD with Color-Coding')\n",
        "plt.xlabel('Actual F1TXMSTD')\n",
        "plt.ylabel('Predicted F1TXMSTD')\n",
        "plt.legend(title='Difference')\n",
        "plt.show()\n",
        "\n",
        "# Get count of points in each category\n",
        "category_counts = selected_df_cleaned['Color'].value_counts()\n",
        "print(\"\\nCount of points in each category:\")\n",
        "print(category_counts)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'\\nMean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "_v2j0bJXzIJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Week 4"
      ],
      "metadata": {
        "id": "1QsHYphwEWMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Regression"
      ],
      "metadata": {
        "id": "vZmMLuUrHIC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the data for training, excluding 'F1TXMSTD'\n",
        "training_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'BYTXMSTD']].copy()\n",
        "# Replace -4, -8, -9 with NaN\n",
        "training_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "training_data_cleaned = training_data.dropna()\n",
        "\n",
        "#training_data_cleaned.drop('F1TXMSTD', axis=1, inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "#X_train = training_data_cleaned.drop('BYTXMSTD', axis=1)\n",
        "X_train = training_data_cleaned\n",
        "y_train = training_data_cleaned['BYTXMSTD']\n",
        "\n",
        "# Train the Multiple Regression model\n",
        "multiple_regression_model = LinearRegression()\n",
        "multiple_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Now, load the data for prediction, excluding 'F1TXMSTD'\n",
        "prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD','BYTXMSTD','BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "#prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_cleaned = prediction_data.dropna()\n",
        "\n",
        "#assign the var\n",
        "actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "\n",
        "#drop traget\n",
        "prediction_data_cleaned.drop('F1TXMSTD', axis=1, inplace=True)\n",
        "\n",
        "# Use the trained model to make predictions on 'F1TXMSTD'\n",
        "predictions_f1txmstd = multiple_regression_model.predict(prediction_data_cleaned.drop('BYTXMSTD', axis=1))\n",
        "#predictions_f1txmstd = multiple_regression_model.predict(prediction_data_cleaned)\n",
        "\n",
        "# Add the predicted values to the DataFrame\n",
        "prediction_data_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "#print(prediction_data_cleaned.head())\n",
        "\n",
        "# Save the DataFrame with predictions to a CSV file if needed\n",
        "# prediction_data_cleaned.to_csv('predicted_output_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "5dGrqRL-JMJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'F1TXMSTD' is the actual target variable in the DataFrame\n",
        "\n",
        "# Extract the actual 'F1TXMSTD' values\n",
        "#actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "\n",
        "# Extract the predicted 'F1TXMSTD' values\n",
        "predicted_f1txmstd = prediction_data_cleaned['Predicted_F1TXMSTD']\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "\n",
        "# Calculate R-squared (R2) score\n",
        "r2 = r2_score(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'R-squared (R2) Score: {r2}')\n"
      ],
      "metadata": {
        "id": "Tux7-fvOlsu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Now, load the data for prediction, excluding 'F1TXMSTD'\n",
        "prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD','BYOCCHS','F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_cleaned = prediction_data.dropna()\n",
        "\n",
        "prediction_data_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd\n",
        "\n",
        "# Calculate the absolute difference between actual and predicted values\n",
        "prediction_data_cleaned['Abs_Difference'] = np.abs(prediction_data_cleaned['F1TXMSTD'] - prediction_data_cleaned['Predicted_F1TXMSTD'])\n",
        "\n",
        "# Color-coding based on the difference\n",
        "prediction_data_cleaned['Color'] = pd.cut(prediction_data_cleaned['Abs_Difference'],\n",
        "                                     bins=[0, 5, 10, 20, 100],\n",
        "                                     labels=['±5', '±10', '±20', '>20'])\n",
        "\n",
        "# Visualize the difference between actual and predicted values using a scatter plot with color-coding\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter_plot = sns.scatterplot(x='F1TXMSTD', y='Predicted_F1TXMSTD', hue='Color', data=prediction_data_cleaned, palette=['green', 'yellow', 'orange', 'red'])\n",
        "plt.title('Actual vs. Predicted F1TXMSTD with Color-Coding')\n",
        "plt.xlabel('Actual F1TXMSTD')\n",
        "plt.ylabel('Predicted F1TXMSTD')\n",
        "plt.legend(title='Difference')\n",
        "plt.show()\n",
        "\n",
        "# Get count of points in each category\n",
        "category_counts = prediction_data_cleaned['Color'].value_counts()\n",
        "print(\"\\nCount of points in each category:\")\n",
        "print(category_counts)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HFraQsMfhczL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {
        "id": "a0iIX_9KPq9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "training_data_knn = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYOCCHS', 'BYTXRSTD', 'BYTXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "training_data_knn.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "training_data_knn_cleaned = training_data_knn.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train_knn = training_data_knn_cleaned.drop('BYTXMSTD', axis=1)\n",
        "#X_train_knn = training_data_knn_cleaned\n",
        "y_train_knn = training_data_knn_cleaned['BYTXMSTD']\n",
        "\n",
        "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors (n_neighbors) as needed\n",
        "knn_model.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "#prediction_data_knn = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYOCCHS', 'BYTXRSTD', 'BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "prediction_data_knn = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYOCCHS', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data_knn.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_knn_cleaned = prediction_data_knn.dropna()\n",
        "\n",
        "# Assign the target variable\n",
        "actual_f1txmstd_knn = prediction_data_knn_cleaned['F1TXMSTD']\n",
        "\n",
        "# Drop target variable\n",
        "prediction_data_knn_cleaned.drop('F1TXMSTD', axis=1, inplace=True)\n",
        "\n",
        "predictions_f1txmstd_knn = knn_model.predict(prediction_data_knn_cleaned)\n",
        "\n",
        "# Add the predicted values to the DataFrame\n",
        "prediction_data_knn_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd_knn\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "#print(prediction_data_knn_cleaned.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "bh96qxuhQTT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the predicted 'F1TXMSTD' values\n",
        "predicted_f1txmstd_knn = prediction_data_knn_cleaned['Predicted_F1TXMSTD']\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse_knn = mean_squared_error(actual_f1txmstd_knn, predicted_f1txmstd_knn)\n",
        "print(f'Mean Squared Error (MSE) for KNN: {mse_knn}')\n",
        "\n",
        "# Calculate R-squared (R2) score\n",
        "r2_knn = r2_score(actual_f1txmstd_knn, predicted_f1txmstd_knn)\n",
        "print(f'R-squared (R2) Score for KNN: {r2_knn}')\n"
      ],
      "metadata": {
        "id": "-SlkHc0HQqb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "R8Ogoxi3RfoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the data for training, excluding 'F1TXMSTD'\n",
        "training_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'BYTXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "training_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "training_data_cleaned = training_data.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train = training_data_cleaned.drop('BYTXMSTD', axis=1)\n",
        "#X_train = training_data_cleaned\n",
        "y_train = training_data_cleaned['BYTXMSTD']\n",
        "\n",
        "# Train the Support Vector Regression model\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Now, load the data for prediction, excluding 'F1TXMSTD'\n",
        "#prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD','BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_cleaned = prediction_data.dropna()\n",
        "\n",
        "# Assign the variable\n",
        "actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "\n",
        "# Drop target\n",
        "prediction_data_cleaned.drop('F1TXMSTD', axis=1, inplace=True)\n",
        "\n",
        "# Use the trained model to make predictions on 'F1TXMSTD'\n",
        "predictions_f1txmstd = svm_model.predict(prediction_data_cleaned)\n",
        "\n",
        "# Add the predicted values to the DataFrame\n",
        "prediction_data_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "#print(prediction_data_cleaned.head())\n",
        "\n",
        "# 'F1TXMSTD' is the actual target variable in the DataFrame\n",
        "\n",
        "# Extract the actual 'F1TXMSTD' values\n",
        "#actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "\n",
        "# Extract the predicted 'F1TXMSTD' values\n",
        "predicted_f1txmstd = prediction_data_cleaned['Predicted_F1TXMSTD']\n",
        "\n"
      ],
      "metadata": {
        "id": "-5-U82V6Rg8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'Mean Squared Error (MSE) for SVM: {mse}')\n",
        "\n",
        "# Calculate R-squared (R2) score\n",
        "r2 = r2_score(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'R-squared (R2) Score for SVM: {r2}')"
      ],
      "metadata": {
        "id": "ZLZvbwDARjaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Regressor"
      ],
      "metadata": {
        "id": "Q1a-EoM2SLQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the data for training, excluding 'F1TXMSTD'\n",
        "training_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'BYTXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "training_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "training_data_cleaned = training_data.dropna()\n",
        "\n",
        "# Separate features and target variable\n",
        "X_train = training_data_cleaned.drop('BYTXMSTD', axis=1)\n",
        "#X_train = training_data_cleaned\n",
        "y_train = training_data_cleaned['BYTXMSTD']\n",
        "\n",
        "# Train the Random Forest Regressor model\n",
        "rf_model = RandomForestRegressor()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Now, load the data for prediction, excluding 'F1TXMSTD'\n",
        "#prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD','BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1','BYOCCHS', 'BYTXRSTD', 'BYTXMSTD', 'F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_cleaned = prediction_data.dropna()\n",
        "\n",
        "# Assign the variable\n",
        "actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "actual_BYTXMSTD = prediction_data_cleaned['BYTXMSTD']\n",
        "\n",
        "# Drop target\n",
        "prediction_data_cleaned.drop('F1TXMSTD', axis=1, inplace=True)\n",
        "prediction_data_cleaned.drop('BYTXMSTD', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# Use the trained model to make predictions on 'F1TXMSTD'\n",
        "predictions_f1txmstd = rf_model.predict(prediction_data_cleaned)\n",
        "\n",
        "#Using best model to make predictions\n",
        "#predictions_f1txmstd = best_rf_model.predict(prediction_data_cleaned)\n",
        "\n",
        "# Add the predicted values to the DataFrame\n",
        "prediction_data_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd\n",
        "\n",
        "# Display the DataFrame with the predicted values\n",
        "#print(prediction_data_cleaned.head())\n",
        "\n",
        "# 'F1TXMSTD' is the actual target variable in the DataFrame\n",
        "\n",
        "# Extract the actual 'F1TXMSTD' values\n",
        "#actual_f1txmstd = prediction_data_cleaned['F1TXMSTD']\n",
        "\n",
        "# Extract the predicted 'F1TXMSTD' values\n",
        "predicted_f1txmstd = prediction_data_cleaned['Predicted_F1TXMSTD']\n",
        "\n",
        "# Add the actual 'F1TXMSTD' values back to the DataFrame\n",
        "prediction_data_cleaned['F1TXMSTD'] = actual_f1txmstd\n",
        "prediction_data_cleaned['BYTXMSTD'] = actual_BYTXMSTD\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7eLKN7Z9SNze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_data_cleaned.head(5))"
      ],
      "metadata": {
        "id": "op38BEaKOaJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CSV of RFR\n",
        "prediction_data_cleaned.to_csv('predicted_output_RFR_02_22.csv', index=False)\n"
      ],
      "metadata": {
        "id": "fDnIV7J6ppiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Hyper Paramter"
      ],
      "metadata": {
        "id": "gVC8s29sV7J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# # Example hyperparameter tuning\n",
        "# param_grid = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "#     'min_samples_split': [2, 5, 10],\n",
        "#     'min_samples_leaf': [1, 2, 4],\n",
        "#     'max_features': ['auto', 'sqrt', 'log2']\n",
        "# }\n",
        "\n",
        "# rf_model = RandomForestRegressor()\n",
        "# grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Best hyperparameters\n",
        "# best_params = grid_search.best_params_\n",
        "# print(f'Best Hyperparameters: {best_params}')\n",
        "\n",
        "# # Use the best model\n",
        "# best_rf_model = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "jJPxy6T3TbwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'Mean Squared Error (MSE) for Random Forest: {mse}')\n",
        "\n",
        "# Calculate R-squared (R2) score\n",
        "r2 = r2_score(actual_f1txmstd, predicted_f1txmstd)\n",
        "print(f'R-squared (R2) Score for Random Forest: {r2}')"
      ],
      "metadata": {
        "id": "r2_gSYn-SQ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Now, load the data for prediction, excluding 'F1TXMSTD'\n",
        "prediction_data = df[['STU_ID', 'BYSEX', 'BYRACE', 'BYSTLANG', 'BYDOB_P', 'BYMOTHED', 'BYFATHED', 'BYSES1', 'BYTXMSTD', 'BYTXRSTD','BYOCCHS','F1TXMSTD']].copy()\n",
        "\n",
        "# Replace -4, -8, -9 with NaN\n",
        "prediction_data.replace([-4, -8, -9], np.nan, inplace=True)\n",
        "\n",
        "# Drop rows with missing values\n",
        "prediction_data_cleaned = prediction_data.dropna()\n",
        "\n",
        "prediction_data_cleaned['Predicted_F1TXMSTD'] = predictions_f1txmstd\n",
        "\n",
        "# Calculate the absolute difference between actual and predicted values\n",
        "prediction_data_cleaned['Abs_Difference'] = np.abs(prediction_data_cleaned['F1TXMSTD'] - prediction_data_cleaned['Predicted_F1TXMSTD'])\n",
        "\n",
        "# Color-coding based on the difference\n",
        "prediction_data_cleaned['Color'] = pd.cut(prediction_data_cleaned['Abs_Difference'],\n",
        "                                     bins=[0, 5, 10, 20, 100],\n",
        "                                     labels=['±5', '±10', '±20', '>20'])\n",
        "\n",
        "# Visualize the difference between actual and predicted values using a scatter plot with color-coding\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter_plot = sns.scatterplot(x='F1TXMSTD', y='Predicted_F1TXMSTD', hue='Color', data=prediction_data_cleaned, palette=['green', 'yellow', 'orange', 'red'])\n",
        "plt.title('Actual vs. Predicted F1TXMSTD with Color-Coding')\n",
        "plt.xlabel('Actual F1TXMSTD')\n",
        "plt.ylabel('Predicted F1TXMSTD')\n",
        "plt.legend(title='Difference')\n",
        "plt.show()\n",
        "\n",
        "# Get count of points in each category\n",
        "category_counts = prediction_data_cleaned['Color'].value_counts()\n",
        "print(\"\\nCount of points in each category:\")\n",
        "print(category_counts)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jU-I_urOeHIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QGho9nevI2Lw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}